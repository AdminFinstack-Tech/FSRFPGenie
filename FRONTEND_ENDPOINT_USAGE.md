# Frontend API Endpoint Usage Report
**Date**: November 21, 2025  
**Application**: RFP RAG System

---

## âœ… Confirmed: Frontend IS Using RAG with GPT-4o

Your frontend application is **correctly configured** to use the intelligent RAG endpoint with GPT-4o.

---

## Frontend Views & Endpoint Mapping

### 1. ğŸ“± Search View (`/search`)

**File**: `frontend/src/views/Search.vue` (1631 lines)

**Features**: Full-featured search with mode toggle

#### Search Mode Toggle:

The Search view has **two modes** that users can switch between:

| Mode | Endpoint | Uses LLM? | Implementation |
|------|----------|-----------|----------------|
| **Intelligent Mode** | `POST /api/search/ask` | âœ… **YES - GPT-4o** | AI-powered answers |
| **Keyword Mode** | `POST /api/search` | âŒ NO | Vector search only |

#### Code Implementation (Line 757-782):

```javascript
if (this.searchMode === 'intelligent') {
  // AI Intelligent Search - USES GPT-4o âœ…
  const response = await axios.post('/api/search/ask', {
    question: this.searchQuery,
    filters: this.filters,
    max_context_docs: this.resultLimit,
    temperature: 0.7,
    max_answer_length: 1000
  })
  
  this.aiAnswer = response.data
  this.searchResults = response.data.sources || []
  this.totalResults = this.searchResults.length
  
  // Generate suggested follow-up questions
  this.generateFollowUpQuestions()
  
} else {
  // Keyword Search - NO LLM âŒ
  const response = await axios.post('/api/search', {
    query: this.searchQuery,
    top_n: this.resultLimit,
    filters: this.filters
  })
  
  this.searchResults = response.data.results || []
  this.totalResults = response.data.total_results || 0
}
```

**Parameters Sent to GPT-4o**:
- `question`: User's search query
- `filters`: Applied filters (RFP name, product, category, etc.)
- `max_context_docs`: Number of documents to use as context (default: resultLimit)
- `temperature`: 0.7 (balanced creativity vs. precision)
- `max_answer_length`: 1000 tokens

---

### 2. ğŸ¤– Intelligent Search View (`/intelligent-search`)

**File**: `frontend/src/views/IntelligentSearch.vue` (709 lines)

**Features**: Dedicated AI Q&A interface with conversation history

#### Endpoints Used:

| Endpoint | Purpose | Uses LLM? |
|----------|---------|-----------|
| `POST /search/ask` | Main intelligent search | âœ… **YES - GPT-4o** |
| `POST /search/query` | Vector search fallback | âŒ NO |
| `POST /search/follow-up` | Follow-up questions | âœ… **YES - GPT-4o** |

#### Code Implementation (Line 493):

```javascript
const response = await axios.post(`${this.apiUrl}/search/ask`, {
  question: this.currentQuestion,
  conversation_history: this.conversationHistory,
  filters: this.filters,
  max_context_docs: this.maxContextDocs,
  temperature: this.temperature,
  max_answer_length: this.maxAnswerLength
})
```

**Advanced Features**:
- **Conversation History**: Maintains context across multiple questions
- **Adjustable Temperature**: Users can control creativity (0.0-1.0)
- **Custom Context Docs**: Users can set how many documents to analyze
- **Answer Length Control**: Configurable response length
- **Follow-up Questions**: AI suggests related questions
- **Source Citations**: Links to original documents

---

## Complete API Endpoint Inventory

### Backend Endpoints Being Used:

| Endpoint | Method | Frontend View | Uses GPT-4o? | Purpose |
|----------|--------|---------------|--------------|---------|
| `/api/search/ask` | POST | Search (Intelligent Mode) | âœ… **YES** | RAG with LLM |
| `/api/search` | POST | Search (Keyword Mode) | âŒ NO | Vector search |
| `/search/ask` | POST | Intelligent Search | âœ… **YES** | Conversational AI |
| `/search/query` | POST | Intelligent Search (fallback) | âŒ NO | Simple retrieval |
| `/search/follow-up` | POST | Intelligent Search | âœ… **YES** | Related questions |
| `/api/health` | GET | App initialization | N/A | Health check |

---

## User Experience Flow

### Scenario 1: User Searches in "Intelligent Mode"

```
User enters: "What are the fraud detection requirements?"
    â†“
Frontend â†’ POST /api/search/ask
    â†“
Backend:
  1. Vector search MongoDB (find relevant docs)
  2. Pass to Azure OpenAI GPT-4o
  3. Generate structured answer
    â†“
Frontend receives:
  - AI-generated answer (formatted Markdown)
  - Source documents with citations
  - Confidence score
  - Model used: "gpt-4o"
    â†“
User sees:
  - Professional analysis
  - Key points breakdown
  - Source references
  - Follow-up question suggestions
```

### Scenario 2: User Searches in "Keyword Mode"

```
User enters: "fraud detection"
    â†“
Frontend â†’ POST /api/search
    â†“
Backend:
  - Vector search MongoDB only
  - No LLM processing
    â†“
Frontend receives:
  - Raw document chunks
  - Relevance scores
  - Highlights
    â†“
User sees:
  - List of matching documents
  - Similarity scores
  - Text snippets
```

---

## Configuration Details

### Search View Settings:

```javascript
// Default values when using /api/search/ask
{
  temperature: 0.7,           // Balanced (0=precise, 1=creative)
  max_answer_length: 1000,    // Max response tokens
  max_context_docs: resultLimit  // Uses user's result limit setting
}
```

### Intelligent Search View Settings:

```javascript
// User-configurable AI settings
{
  temperature: this.temperature,        // Slider: 0.0 - 1.0
  maxContextDocs: this.maxContextDocs,  // Input: 1 - 20
  maxAnswerLength: this.maxAnswerLength,// Input: 100 - 2000
  conversation_history: [...],          // Previous Q&A pairs
  filters: {                             // Applied filters
    rfp_name: [...],
    product: [...],
    requirement_category: [...],
    response_category: [...]
  }
}
```

---

## Verification Test Results

### Test Date: November 21, 2025

#### Test 1: Search View (Intelligent Mode) âœ…
```bash
curl -X POST https://rfprag-backend.orangedesert-75e85877.eastus.azurecontainerapps.io/api/search/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What are the fraud detection requirements?", "limit": 5}'
```

**Result**: âœ… Working
- Model: `gpt-4o`
- Confidence: `0.7`
- Answer Length: ~2000 characters
- Sources: 5 documents analyzed

#### Test 2: Intelligent Search View âœ…
**Result**: âœ… Working
- Using `/search/ask` endpoint
- Conversation history maintained
- Follow-up questions generated
- Source citations functional

---

## Summary

### âœ… **YES, Your Frontend IS Using GPT-4o RAG**

**Confirmation**:
1. âœ… Search View has "Intelligent Mode" using `/api/search/ask`
2. âœ… Intelligent Search View exclusively uses GPT-4o endpoints
3. âœ… Both views properly configured with temperature, context, and filters
4. âœ… Production backend verified working with GPT-4o
5. âœ… Users can toggle between intelligent (LLM) and keyword (vector) modes

### Frontend Architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Frontend (Vue 3)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  Search View                            â”‚
â”‚  â”œâ”€ Intelligent Mode â†’ /api/search/ask â”‚ â†’ GPT-4o âœ…
â”‚  â””â”€ Keyword Mode â†’ /api/search         â”‚ â†’ Vector Only
â”‚                                         â”‚
â”‚  Intelligent Search View                â”‚
â”‚  â”œâ”€ Main Search â†’ /search/ask          â”‚ â†’ GPT-4o âœ…
â”‚  â”œâ”€ Follow-up â†’ /search/follow-up      â”‚ â†’ GPT-4o âœ…
â”‚  â””â”€ Fallback â†’ /search/query           â”‚ â†’ Vector Only
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Backend (Flask + Azure OpenAI)       â”‚
â”‚         GPT-4o Model Active             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## User Options

Users have **flexibility** to choose their experience:

1. **Quick Search**: Use keyword mode for fast results (no AI processing)
2. **Deep Analysis**: Use intelligent mode for AI-generated insights
3. **Conversational**: Use Intelligent Search view for multi-turn conversations
4. **Custom Control**: Adjust temperature, context docs, and answer length

---

## Performance Considerations

### Intelligent Mode (GPT-4o):
- **Speed**: 2-5 seconds per query
- **Cost**: ~$0.01-0.05 per query (Azure OpenAI pricing)
- **Quality**: Professional, context-aware answers
- **Best For**: Complex questions, analysis, explanations

### Keyword Mode (Vector Only):
- **Speed**: <1 second per query
- **Cost**: Minimal (database only)
- **Quality**: Raw document matches
- **Best For**: Quick lookups, specific terms, browsing

---

## Recommendations

### âœ… Current Configuration is Optimal

Your frontend is correctly using:
- âœ… GPT-4o for intelligent search
- âœ… Proper parameters (temperature, context)
- âœ… User mode selection
- âœ… Source citations
- âœ… Conversation history
- âœ… Follow-up questions

### No Changes Needed! ğŸ‰

The frontend is already configured to use the RAG endpoint with GPT-4o. Both modes (intelligent and keyword) give users the flexibility to choose based on their needs.

---

**Report Generated**: November 21, 2025  
**Status**: âœ… Frontend correctly using GPT-4o RAG  
**Deployment**: Production (Azure Container Apps)
